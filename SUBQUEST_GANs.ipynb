{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks : Some applications being currently explored\n",
    "\n",
    "### Jonatan Pi√±ol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complement the explanation on GANs, my contribution will be based on exploring some applications of GANs for Image and Speech Processing that I find very interesting and illustrative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first recall the main elements of a GAN in a probabilistic way. As it was stated in the previous contribution for this subquest, the GAN is mainly composed of two networks: Generative network (G) and Discriminant network (D)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the whole system as a model that learns to map the samples $z$ (latent vector) from a distribution $Z$, to samples $x$ from a distribution $X$. The element that performs this mapping is the Generative network (G) (mapping G($z$) $\\approx x$). But before that, G must learn how to perform this mapping (not by learning input-output pairs) in order to generate new content related to the training data.\n",
    "\n",
    "For the learning process of G, there is the discriminative network (D) that is a network that acts like a classifier. D gets as inputs two types of data: the \"real samples\" (that comes form a distribution $X$) that G tries to imitate and the \"fake samples\" (that follow a distribution $\\hat{X}$) that G generates. D has to correctly classify its inputs as \"real\" or \"fake\" and G to improve the generation of samples in order to \"fool\" D, so each time during backpropagation each network adapts its parameters to accomplish their objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this architecture has lead to some interesting applications in image and speech:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Visual Manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was presented by Zhu et al. 2016 (https://arxiv.org/abs/1609.03552).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case the problem that is dealed is the modeling of natural image manifold. The proposed solution is using a GAN structure. The novelty of their proposal is that they don't use the GAN to generate new samples that ressembles of the natural image manifold, but they use it to constraint the manipulations done on an image such that they lie on the learned natural image manifold (in other words given an image, a user edits it, and the system automatically adjusts this edition in a way that the output is as realistic as possible independently of the user proficency on image edition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the GAN is trained to model the natural image manifold for one class of images (for example it can be trained to model the class \"shoes\") in the usual way for GANs i.e. G generates fake images that are close to real ones in the manifold and D try to discriminate the fake from the real. Once G is properly trained, given a real image $x$ the goal is to find the latent vector $z_0$ such that G($z_0$)$ \\approx x$. From this point each edition that the user do is projected to the manifold and a new $z_1$ is found such that is as close as possible to \"edited\" $z_0$, so that the generated edited image G($z_1$) = $x_1$ still belongs to the modeled natural image manifold.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end they propose some applications using the described GAN structure:\n",
    "\n",
    "+ **Image Manipulation** : Using a \"brush\" a user can edit an existant image and the system will output this edits on a realistic result. The edition capabilities are limited to color edition and shape edition. The following figure  (from Zhu et al. 2016 https://arxiv.org/abs/1609.03552) shows the process, following the steps explained before.\n",
    "![title](zhu_gan_1.png)\n",
    "\n",
    "+ **Interactive Image Generation** : Without a base image, a user using a \"brush\" can sketch an image, and the sytem will generate a natural image that satisfies the sketch. The following figure (from Zhu et al. 2016 https://arxiv.org/abs/1609.03552) shows three cases. The first three rows concerns the generation process from user sketches and the fourth row is the resulting generated image compared to the three most similar real images.\n",
    "![title](zhu_gan_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Youtube URLs show both examples in action:\n",
    "\n",
    "Image Manipulation: https://www.youtube.com/watch?v=9c4z6YsBGQ0&feature=youtu.be&t=126\n",
    "\n",
    "Interactive Image Generation: https://www.youtube.com/watch?v=9c4z6YsBGQ0&feature=youtu.be&t=161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Enhancement Generative Adversarial Network (SEGAN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This application is very interesting, as opposite to most of applications this one is one of the few that is not on Image Processing domain. This application was presented by Santiago Pascual et al. 2017 (https://arxiv.org/abs/1703.09452) from the Center for Language and Speech Technologies and Applications (TALP), from UPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the enhancement problem for speech signals is explored and a solution is proposed. The enhancement consist on, given a noisy speech signal ($\\tilde{x}$), clean it in order to obtain a clean signal $\\hat{x}$ that resembles $x$ (the ground truth signal). The proposed solution is using a GAN structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, G is trained to perform the enhancement. It has as input the noisy signal and its output should be the cleaned enhanced one. In order to attain this, D is trained previously to discriminate between a noisy signal and a clean signal. Once D is able to classify, G is introduced to begin generating enhanced signals that are the input for D. D is designed with two goals, either classify the output of G as \"fake\" or \"real\" signals, and in both cases transmit to G what is \"fake\" or \"real\", so G can correct its output toward a more \"realistic\" waveform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure from Santiago Pacual et al. 2017 summarizes the learning process. \n",
    "\n",
    "![title](segan_learning2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example also deals with the structure of G to better process this kind of signals: \n",
    "\n",
    "For example, G is built using autoencoder structure with connections from the layers of the encoder and decoder part so the low level detail components are not lost because they don't pass through the compression and decompression process, and being able to reconstruct the speech waveform without detail loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following URL it is possible to see (in this case listen) to some experiments. The samples are noisy samples, enhanced signals using Wiener Filtering (a filter that estimates a target signal from an observed noisy signal) and the proposed SEGAN.\n",
    "\n",
    "http://veu.talp.cat/segan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
